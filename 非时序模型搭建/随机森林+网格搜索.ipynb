{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0f7f39",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#随机森林+网格搜索，线下CV得分3.6857\" data-toc-modified-id=\"随机森林+网格搜索，线下CV得分3.6857-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>随机森林+网格搜索，线下CV得分3.6857</a></span><ul class=\"toc-item\"><li><span><a href=\"#特征筛选-相关系数筛选\" data-toc-modified-id=\"特征筛选-相关系数筛选-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>特征筛选-相关系数筛选</a></span></li><li><span><a href=\"#参数调优-网格搜索\" data-toc-modified-id=\"参数调优-网格搜索-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>参数调优-网格搜索</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2780e7",
   "metadata": {},
   "source": [
    "# 随机森林+网格搜索，线下CV得分3.6857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34016bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T03:46:47.272570Z",
     "start_time": "2024-04-19T03:46:47.261441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n特征组合：Dict+GroupBy\\n特征选择方式：Pearson\\n参数寻优办法：GridSearch\\n模型：randomforest\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "特征组合：Dict+GroupBy\n",
    "特征选择方式：Pearson\n",
    "参数寻优办法：GridSearch\n",
    "模型：randomforest\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1bbdeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T03:46:48.231237Z",
     "start_time": "2024-04-19T03:46:47.274446Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def read_data(debug=True):\n",
    "    \"\"\"\n",
    "    读取数据\n",
    "    :param debug:是否调试版，可以极大节省debug时间\n",
    "    :return:训练集，测试集\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"read_data...\")\n",
    "    NROWS = 10000 if debug else None # 如果debug就只取前10000行 \n",
    "    train_dict = pd.read_csv(\"preprocess/train_dict.csv\", nrows=NROWS) #nrows=None是读取全部行\n",
    "    test_dict = pd.read_csv(\"preprocess/test_dict.csv\", nrows=NROWS)\n",
    "    train_groupby = pd.read_csv(\"preprocess/train_groupby.csv\", nrows=NROWS)\n",
    "    test_groupby = pd.read_csv(\"preprocess/test_groupby.csv\", nrows=NROWS)\n",
    "\n",
    "    # 去除重复列\n",
    "    for col in train_dict.columns:\n",
    "        if col in train_groupby.columns and col!='card_id':\n",
    "            del train_groupby[col]\n",
    "    for col in test_dict.columns:\n",
    "        if col in test_groupby.columns and col!='card_id':\n",
    "            del test_groupby[col]\n",
    "\n",
    "    # 拼接特征\n",
    "    train = pd.merge(train_dict, train_groupby, how='left', on='card_id').fillna(0)\n",
    "    test = pd.merge(test_dict, test_groupby, how='left', on='card_id').fillna(0)\n",
    "    print(\"done\")\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f270fba",
   "metadata": {},
   "source": [
    "## 特征筛选-相关系数筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7b2ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T03:46:48.236704Z",
     "start_time": "2024-04-19T03:46:48.232201Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_select_pearson(train, test):\n",
    "    #pearson相关系数就是最常见的相关系数\n",
    "    \"\"\"\n",
    "    利用pearson相关系数进行相关性特征选择\n",
    "    :param train:训练集\n",
    "    :param test:测试集\n",
    "    :return:经过特征选择后的训练集与测试集\n",
    "    \"\"\"\n",
    "    print('feature_select...')\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(\"card_id\")\n",
    "    features.remove(\"target\")\n",
    "    featureSelect = features[:]\n",
    "\n",
    "    # 去掉缺失值比例超过0.99的\n",
    "    for feature in features:\n",
    "        if train[feature].isnull().sum() / train.shape[0] >= 0.99:\n",
    "            featureSelect.remove(feature)\n",
    "\n",
    "    # 进行pearson相关性计算\n",
    "    corr = []\n",
    "    for feature in featureSelect:\n",
    "        corr.append(abs(train[[feature, 'target']].fillna(0).corr().values[0][1]))#注意这个是2维array，类似于C++数组风格\n",
    "\n",
    "    # 取top300的特征进行建模，具体数量可选\n",
    "    se = pd.Series(corr, index=featureSelect).sort_values(ascending=False)\n",
    "    feature_select = ['card_id'] + se[:300].index.tolist()\n",
    "    print('done')\n",
    "    return train[feature_select + ['target']], test[feature_select]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc04fcf",
   "metadata": {},
   "source": [
    "## 参数调优-网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa72d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T03:46:22.764524Z",
     "start_time": "2024-04-19T03:46:22.764517Z"
    }
   },
   "source": [
    "<font color=red>网格搜索同样是交叉验证确定最优参数</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17bc9fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T03:49:17.494779Z",
     "start_time": "2024-04-19T03:49:17.482313Z"
    }
   },
   "outputs": [],
   "source": [
    "def param_grid_search(train):\n",
    "    \"\"\"\n",
    "    网格搜索参数寻优\n",
    "    :param train:训练集\n",
    "    :return:最优的分类器模型\n",
    "    \"\"\"\n",
    "    print('param_grid_search')\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(\"card_id\")\n",
    "    features.remove(\"target\")\n",
    "    \n",
    "    parameter_space = {\n",
    "        \"n_estimators\": [80],\n",
    "        \"min_samples_leaf\": [30],\n",
    "        \"min_samples_split\": [2],\n",
    "        \"max_depth\": [9],\n",
    "        \"max_features\": ['sqrt','log2',100]\n",
    "    }\n",
    "\n",
    "    print(\"Tuning hyper-parameters for mse\")\n",
    "    clf = RandomForestRegressor(\n",
    "        criterion=\"squared_error\",\n",
    "        min_weight_fraction_leaf=0.,#类似于min_samples_leaf，不过这里按照权重而不是数目\n",
    "        max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0., #设置最低不纯度，低于这个值就不再分叉了\n",
    "        bootstrap=True,\n",
    "        oob_score=False,\n",
    "        n_jobs=8,\n",
    "        random_state=2020,\n",
    "        verbose=0,\n",
    "        warm_start=False)\n",
    "    grid = GridSearchCV(clf, parameter_space, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    grid.fit(train[features].values, train['target'].values)\n",
    "\n",
    "    print(\"best_params_:\")\n",
    "    print(grid.best_params_)\n",
    "    print('====================================================================')\n",
    "    means = grid.cv_results_[\"mean_test_score\"]#5折后的mean\n",
    "    stds = grid.cv_results_[\"std_test_score\"]\n",
    "    i = 1\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_[\"params\"]):\n",
    "        print(f'第{i}组参数:')\n",
    "        i+=1\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    return grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967ebe12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T03:56:35.196591Z",
     "start_time": "2024-04-19T03:49:30.933833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_data...\n",
      "done\n",
      "feature_select...\n",
      "done\n",
      "param_grid_search\n",
      "Tuning hyper-parameters for mse\n",
      "best_params_:\n",
      "{'max_depth': 9, 'max_features': 100, 'min_samples_leaf': 30, 'min_samples_split': 2, 'n_estimators': 80}\n",
      "====================================================================\n",
      "第1组参数:\n",
      "-13.720 (+/-0.110) for {'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 30, 'min_samples_split': 2, 'n_estimators': 80}\n",
      "第2组参数:\n",
      "-13.862 (+/-0.115) for {'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 30, 'min_samples_split': 2, 'n_estimators': 80}\n",
      "第3组参数:\n",
      "-13.631 (+/-0.087) for {'max_depth': 9, 'max_features': 100, 'min_samples_leaf': 30, 'min_samples_split': 2, 'n_estimators': 80}\n",
      "train_predict...\n",
      "3.6900584289655423\n",
      "第0次结束\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/var/folders/5n/0d0v__td7sd265lmdhjw1h440000gn/T/ipykernel_20444/2827353848.py:30: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  prediction_train = pd.concat([prediction_train,pd.Series(best_clf.predict(train[features].loc[eval_index]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.650674457367465\n",
      "第1次结束\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.713631059161725\n",
      "第2次结束\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7894171753660055\n",
      "第3次结束\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5846883710434545\n",
      "第4次结束\n",
      "[3.6900584289655423, 3.650674457367465, 3.713631059161725, 3.7894171753660055, 3.5846883710434545] 3.685693898380839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_predict(train, test, best_clf):\n",
    "    \"\"\"\n",
    "    进行训练和预测输出结果\n",
    "    :param train:训练集\n",
    "    :param test:测试集\n",
    "    :param best_clf:最优的分类器模型\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print('train_predict...')\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(\"card_id\")\n",
    "    features.remove(\"target\")\n",
    "\n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series()\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    for i,(train_part_index, eval_index) in enumerate(kf.split(train[features], train['target'])):\n",
    "        best_clf.fit(train[features].loc[train_part_index].values, train['target'].loc[train_part_index].values)\n",
    "        prediction_test += best_clf.predict(test[features].values)#这是预测test，跟val无关\n",
    "        eval_pre = best_clf.predict(train[features].loc[eval_index].values)\n",
    "        \n",
    "        #评价函数\n",
    "        score = np.sqrt(mean_squared_error(train['target'].loc[eval_index].values, eval_pre))\n",
    "        cv_score.append(score)\n",
    "        print(score)\n",
    "        \n",
    "        #拼接每次在验证集上的预测结果，得到全部训练集的预测结果\n",
    "        prediction_train = pd.concat([prediction_train,pd.Series(best_clf.predict(train[features].loc[eval_index]),\n",
    "                                                             index=eval_index)])\n",
    "        print(f'第{i}次结束')\n",
    "    print(cv_score, sum(cv_score) / 5)\n",
    "    \n",
    "    #保存\n",
    "    pd.Series(prediction_train.sort_index().values).to_csv(\"preprocess/train_randomforest.csv\", index=False)\n",
    "    pd.Series(prediction_test / 5).to_csv(\"preprocess/test_randomforest.csv\", index=False)\n",
    "    \n",
    "    #提交submission.csv\n",
    "    test['target'] = prediction_test / 5\n",
    "    test[['card_id', 'target']].to_csv(\"result/submission_randomforest.csv\", index=False)\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 获取训练集与测试集\n",
    "    train, test = read_data(debug=False)\n",
    "\n",
    "    # 获取特征选择结果\n",
    "    train, test = feature_select_pearson(train, test)\n",
    "\n",
    "    # 获取最优分类器模型\n",
    "    best_clf = param_grid_search(train)\n",
    "\n",
    "    # 获取结果\n",
    "    train_predict(train, test, best_clf)\n",
    "# [3.6952175995861753, 3.653405245049519, 3.711542672510601, 3.78859477721067, 3.586786511640954] 3.687109361199584\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c1093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
