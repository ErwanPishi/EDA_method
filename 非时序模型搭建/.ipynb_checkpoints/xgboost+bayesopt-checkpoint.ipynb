{
 "cells": [
  {
   "cell_type": "raw",
   "id": "629f053b",
   "metadata": {},
   "source": [
    "# bayesopt只能支持连续型变量，很拉，不建议用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43e6b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:37:27.667024Z",
     "start_time": "2024-04-27T12:37:25.742138Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "特征组合：Dict+GroupBy+nlp\n",
    "特征选择方式：chi2\n",
    "参数寻优办法：beyesian\n",
    "模型：xgboost\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from scipy import sparse\n",
    "from sklearn.feature_selection import f_regression\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "path = '/Volumes/U397/机器学习/机器学习比赛/机器学习算法竞赛实战/第8章 kaggle 信用卡忠诚度预测/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f6d1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:37:27.671684Z",
     "start_time": "2024-04-27T12:37:27.668176Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(debug=True):\n",
    "    \"\"\"\n",
    "\n",
    "    :param debug:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"read_data...\")\n",
    "    NROWS = 10000 if debug else None\n",
    "    train_dict = pd.read_csv(path+\"preprocess/train_dict.csv\", nrows=NROWS)\n",
    "    test_dict = pd.read_csv(path+\"preprocess/test_dict.csv\", nrows=NROWS)\n",
    "    train_groupby = pd.read_csv(path+\"preprocess/train_groupby.csv\", nrows=NROWS)\n",
    "    test_groupby = pd.read_csv(path+\"preprocess/test_groupby.csv\", nrows=NROWS)\n",
    "\n",
    "    # 去除重复列\n",
    "    for co in train_dict.columns:\n",
    "        if co in train_groupby.columns and co!='card_id':\n",
    "            del train_groupby[co]\n",
    "    for co in test_dict.columns:\n",
    "        if co in test_groupby.columns and co!='card_id':\n",
    "            del test_groupby[co]\n",
    "\n",
    "    train = pd.merge(train_dict, train_groupby, how='left', on='card_id').fillna(0)\n",
    "    test = pd.merge(test_dict, test_groupby, how='left', on='card_id').fillna(0)\n",
    "\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "\n",
    "    train_x = sparse.load_npz(path+\"preprocess/train_nlp.npz\")\n",
    "    test_x = sparse.load_npz(path+\"preprocess/test_nlp.npz\")\n",
    "\n",
    "    train_x = sparse.hstack((train_x, train[features])).tocsr()#合并成sparse矩阵\n",
    "    test_x = sparse.hstack((test_x, test[features])).tocsr()#合并成sparse矩阵\n",
    "    print(\"done\")\n",
    "    return train_x, test_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec2ed4",
   "metadata": {},
   "source": [
    "# bayesopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad8c328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:37:27.677101Z",
     "start_time": "2024-04-27T12:37:27.672489Z"
    }
   },
   "outputs": [],
   "source": [
    "def params_append(params):\n",
    "    \"\"\"\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    params['objective'] = 'reg:squarederror'\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    params[\"min_child_weight\"] = int(params[\"min_child_weight\"]) #改成整数类型\n",
    "    params['max_depth'] = int(params['max_depth']) #改成整数类型\n",
    "    return params\n",
    "\n",
    "\n",
    "def param_beyesian(train):\n",
    "    \"\"\"\n",
    "    :param train:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_y = pd.read_csv(path+\"data/train.csv\")['target']\n",
    "    train_data = xgb.DMatrix(train.tocsr(),\n",
    "                             train_y.values, \n",
    "                             silent=True)\n",
    "    \n",
    "    def bayesopt_objective(colsample_bytree, subsample,\n",
    "                           min_child_weight, max_depth,\n",
    "                           reg_alpha, reg_lambda, eta):#优化的目标函数\n",
    "        params = {'objective': 'reg:squarederror',\n",
    "                  'eval_metric': 'rmse'}\n",
    "        params['colsample_bytree'] = max(min(colsample_bytree, 1), 0) #这里是确保为正\n",
    "        params['subsample'] = max(min(subsample, 1), 0) #这里是确保为正\n",
    "        params[\"min_child_weight\"] = int(min_child_weight) #这里是确保为整数\n",
    "        params['max_depth'] = int(max_depth) #这里是确保为整数\n",
    "        params['eta'] = float(eta)\n",
    "        params['reg_alpha'] = max(reg_alpha, 0)  #这里是确保为整数\n",
    "        params['reg_lambda'] = max(reg_lambda, 0)  #这里是确保为整数\n",
    "        #print(params)\n",
    "        \n",
    "        cv_result = xgb.cv(params, train_data,\n",
    "                           num_boost_round=1000,\n",
    "                           nfold=2, seed=2,\n",
    "                           stratified=False,\n",
    "                           shuffle=True,\n",
    "                           early_stopping_rounds=30,\n",
    "                           verbose_eval=False)\n",
    "        #cv_result记录了每一颗树的eval_metric,因此test-rmse-mean中的最小值即对应最后的最优结果\n",
    "        return -min(cv_result['test-rmse-mean'])#bayes-opt是最大化，所以这里加负号 \n",
    "    \n",
    "    xgb_bo = BayesianOptimization(\n",
    "        bayesopt_objective,\n",
    "        {'colsample_bytree': (0.5, 1),\n",
    "         'subsample': (0.5, 1),\n",
    "         'min_child_weight': (1, 30),\n",
    "         'max_depth': (5, 12),\n",
    "         'reg_alpha': (0, 5),\n",
    "         'eta':(0.02, 0.2),\n",
    "         'reg_lambda': (0, 5)}\n",
    "    )\n",
    "    xgb_bo.maximize(init_points=21, n_iter=5)  # init_points表示初始点，n_iter代表迭代次数（即采样数）\n",
    "    print(xgb_bo.max['target'], xgb_bo.max['params'])\n",
    "    return xgb_bo.max['params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea345c0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-27T12:37:25.742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_data...\n",
      "done\n",
      "|   iter    |  target   | colsam... |    eta    | max_depth | min_ch... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "{'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'colsample_bytree': 0.7308046880994747, 'subsample': 0.5896472861648605, 'min_child_weight': 21, 'max_depth': 6, 'eta': 0.17699413134901845, 'reg_alpha': 1.5650410736509723, 'reg_lambda': 2.6196802076219017}\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-3.702   \u001b[0m | \u001b[0m0.7308   \u001b[0m | \u001b[0m0.177    \u001b[0m | \u001b[0m6.68     \u001b[0m | \u001b[0m21.67    \u001b[0m | \u001b[0m1.565    \u001b[0m | \u001b[0m2.62     \u001b[0m | \u001b[0m0.5896   \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'colsample_bytree': 0.5684544762437197, 'subsample': 0.9788778842283206, 'min_child_weight': 25, 'max_depth': 6, 'eta': 0.12319646416386952, 'reg_alpha': 0.7311744821287564, 'reg_lambda': 1.878122346316694}\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-3.691   \u001b[0m | \u001b[95m0.5685   \u001b[0m | \u001b[95m0.1232   \u001b[0m | \u001b[95m6.363    \u001b[0m | \u001b[95m25.21    \u001b[0m | \u001b[95m0.7312   \u001b[0m | \u001b[95m1.878    \u001b[0m | \u001b[95m0.9789   \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'colsample_bytree': 0.5326083314284835, 'subsample': 0.7195698438849778, 'min_child_weight': 29, 'max_depth': 5, 'eta': 0.12842741601734345, 'reg_alpha': 4.588381620724731, 'reg_lambda': 1.2268109874163176}\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-3.69    \u001b[0m | \u001b[95m0.5326   \u001b[0m | \u001b[95m0.1284   \u001b[0m | \u001b[95m5.157    \u001b[0m | \u001b[95m29.29    \u001b[0m | \u001b[95m4.588    \u001b[0m | \u001b[95m1.227    \u001b[0m | \u001b[95m0.7196   \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'colsample_bytree': 0.6657092558719682, 'subsample': 0.9590194265682044, 'min_child_weight': 28, 'max_depth': 10, 'eta': 0.022594316072491308, 'reg_alpha': 4.1915349520843135, 'reg_lambda': 2.7715178155505664}\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m-3.68    \u001b[0m | \u001b[95m0.6657   \u001b[0m | \u001b[95m0.02259  \u001b[0m | \u001b[95m10.29    \u001b[0m | \u001b[95m28.42    \u001b[0m | \u001b[95m4.192    \u001b[0m | \u001b[95m2.772    \u001b[0m | \u001b[95m0.959    \u001b[0m |\n",
      "{'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'colsample_bytree': 0.8420180895796989, 'subsample': 0.8200440678225132, 'min_child_weight': 4, 'max_depth': 10, 'eta': 0.05394057884957726, 'reg_alpha': 3.662836669731644, 'reg_lambda': 3.6180121953457696}\n"
     ]
    }
   ],
   "source": [
    "def train_predict(train, test, params):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train:\n",
    "    :param test:\n",
    "    :param params:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_y = pd.read_csv(path+\"data/train.csv\")['target']\n",
    "    test_data = xgb.DMatrix(test)\n",
    "\n",
    "    params = params_append(params)\n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series(None,index=train_y.index)\n",
    "    ESR = 30     #early_stopping_rounds\n",
    "    NBR = 10000  #num_boost_rounds\n",
    "    VBE = 50     #verbose_eval\n",
    "    for i,(train_part_index, val_index) in enumerate(kf.split(train, train_y)):\n",
    "        # 模型训练\n",
    "        train_part = xgb.DMatrix(train.tocsr()[train_part_index, :],\n",
    "                                 train_y.loc[train_part_index])\n",
    "        val_part = xgb.DMatrix(train.tocsr()[val_index, :],\n",
    "                           train_y.loc[val_index])\n",
    "        #bst是boost，不是best\n",
    "        bst = xgb.train(params, train_part, NBR, \n",
    "                        evals=[(train_part, 'train'),(val_part, 'eval')], \n",
    "                        verbose_eval=VBE,\n",
    "                        maximize=False, \n",
    "                        early_stopping_rounds=ESR)\n",
    "        prediction_test += bst.predict(test_data)\n",
    "        val_pre = bst.predict(val_part)\n",
    "        prediction_train = pd.concat([prediction_train,pd.Series(val_pre, index=val_index)],ignore_index=False)\n",
    "        score = np.sqrt(mean_squared_error(train_y.loc[val_index].values, val_pre))\n",
    "        cv_score.append(score)\n",
    "    print(cv_score, sum(cv_score) / 5)\n",
    "    pd.Series(prediction_train.sort_index().values).to_csv(path+\"preprocess/train_xgboost.csv\", index=False)\n",
    "    pd.Series(prediction_test / 5).to_csv(path+\"preprocess/test_xgboost.csv\", index=False)\n",
    "    test = pd.read_csv(path+'data/test.csv')\n",
    "    test['target'] = prediction_test / 5\n",
    "    test[['card_id', 'target']].to_csv(path+\"result/submission_xgboost.csv\", index=False)\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train, test = read_data(debug=False)\n",
    "    best_clf = param_beyesian(train)\n",
    "    train_predict(train, test, best_clf)\n",
    "# [3.6799306462307517, 3.6476521867457588, 3.698480976611057, 3.7718461304040853, 3.579301270046094] 3.6754422420075494"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b72c0",
   "metadata": {},
   "source": [
    "# 对比hyperopt 施工中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffaed7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-27T12:37:25.743Z"
    }
   },
   "outputs": [],
   "source": [
    "def params_append1(params):\n",
    "    params['objective'] = 'reg:squarederror'\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    return params\n",
    "\n",
    "def param_hyperopt(train):\n",
    "    \"\"\"\n",
    "    返回最佳参数\n",
    "    :param train:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "    train_y = pd.read_csv(path+\"data/train.csv\")['target']\n",
    "    train_data = xgb.DMatrix(train.tocsr(),train_y.values, silent=True)\n",
    "    def hyperopt_objective(params):#优化的目标函数\n",
    "        \"\"\"\n",
    "        :param params:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        params = params_append(params)\n",
    "        cv_result = xgb.cv(params, train_data,\n",
    "                           num_boost_round=1000,\n",
    "                           nfold=2, seed=2,\n",
    "                           stratified=False,\n",
    "                           shuffle=True,\n",
    "                           early_stopping_rounds=30,\n",
    "                           verbose_eval=False)\n",
    "        return min(cv_result['test-rmse-mean'])\n",
    "    \n",
    "    params_space = {\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        'subsample': hp.uniform('subsample',0.5, 1),\n",
    "        'min_child_weight': hp.randint('min_child_weight',1, 30),\n",
    "        'max_depth': hp.randint('max_depth', 5, 12),\n",
    "        'reg_alpha': hp.randint('reg_alpha', 0, 5),\n",
    "        'eta': hp.uniform('eta',0.02, 0.2),\n",
    "        'reg_lambda': hp.uniform('reg_lambda',0, 5)\n",
    "        }\n",
    "    #fmin:Minimize a function over a hyperparameter space.\n",
    "    params_best = fmin(\n",
    "        hyperopt_objective,\n",
    "        space=params_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=30,\n",
    "        rstate=np.random.default_rng(2020))\n",
    "    return params_best\n",
    "\n",
    "def train_predict1(train, test, params):\n",
    "    train_y = pd.read_csv(path+\"data/train.csv\")['target']\n",
    "    test_data = xgb.DMatrix(test)\n",
    "\n",
    "    params = params_append1(params)\n",
    "    kf = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series(None,index=train_y.index)\n",
    "    ESR = 30     #early_stopping_rounds\n",
    "    NBR = 10000  #num_boost_rounds\n",
    "    VBE = 50     #verbose_eval\n",
    "    for i,(train_part_index, val_index) in enumerate(kf.split(train, train_y)):\n",
    "        # 模型训练\n",
    "        train_part = xgb.DMatrix(train.tocsr()[train_part_index, :],\n",
    "                                 train_y.loc[train_part_index])\n",
    "        val_part = xgb.DMatrix(train.tocsr()[val_index, :],\n",
    "                           train_y.loc[val_index])\n",
    "        #bst是boost，不是best\n",
    "        bst = xgb.train(params, train_part, NBR, \n",
    "                        evals=[(train_part, 'train'),(val_part, 'eval')], \n",
    "                        verbose_eval=VBE,\n",
    "                        maximize=False, \n",
    "                        early_stopping_rounds=ESR)\n",
    "        prediction_test += bst.predict(test_data)\n",
    "        val_pre = bst.predict(val_part)\n",
    "        prediction_train = pd.concat([prediction_train,pd.Series(val_pre, index=val_index)],ignore_index=False)\n",
    "        score = np.sqrt(mean_squared_error(train_y.loc[val_index].values, val_pre))\n",
    "        cv_score.append(score)\n",
    "    print(cv_score, sum(cv_score) / 5)\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train, test = read_data(debug=False)\n",
    "    best_clf = param_hyperopt(train)\n",
    "    train_predict1(train, test, best_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
